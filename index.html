<!DOCTYPE html>
<!-- <script src="https://cdn.jsdelivr.net/npm/vue"></script> -->
<link rel="stylesheet" href="http://newfront.free4inno.com/bootstrap/css/bootstrap.min.css">
<link rel="stylesheet" href="http://newfront.free4inno.com/css/front.css">
<html lang="en-us">
<!-- <head>
    <meta http-equiv="content-type" content="text/html;charset=utf-8"/>
    <title>The First International Workshop on Human and Vehicle Analysis for Intelligent Urban Computing</title>
</head> -->
<head>
    <meta charset="UTF-8">
    <title>HAVAIUC</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="css/normalize.css" media="screen">
    <link rel="stylesheet" type="text/css" href="css/cayman.css" media="screen">
    <link rel="stylesheet" type="text/css" href="css/github-light.css" media="screen">
  </head>
<body>
<!-- <div name='title'>
    <h2>Time</h2>
    <p>Milan, Italy, 13 Sep. 2020</p>
</div> -->
    <section class="page-header">
        <h1 class="project-name">The First International Workshop on Human and Vehicle Analysis for Intelligent Urban Computing</h1>
        <h2 class="project-tagline">ICPR 2020, Milan, Italy, 13 Sep. 2020</h2>
        <!-- <a href="https://github.com/jasonlong/cayman-theme" class="btn">View on GitHub</a>
        <a href="https://github.com/jasonlong/cayman-theme/zipball/master" class="btn">Download .zip</a>
        <a href="https://github.com/jasonlong/cayman-theme/tarball/master" class="btn">Download .tar.gz</a> -->
    </section>
<section class="main-content">
<div name='News'>
    <h2>News</h2>
    <ul>
        <li>The webpage is available</li>
    </ul>
</div>
<div name='Overview'>
    <h1>
        <a id="header-1" class="anchor" href="#header-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>
        Overview
    </h1>
    <p>
        The rapid proliferation of urbanization has modernized people’s lives and at the same time engendered critical challenges, such as traffic congestion, energy consumption, public security, and environmental pollution. Today, multiple multimedia sensing technologies and large-scale computing infrastructures are producing at a rapid velocity a wide variety of big multi-modality data in urban spaces, which provide rich knowledge about a city to help tackle these challenges. Consequently, intelligent urban computing has been attracting increasing attention from academia and industry. Among them, human analysis and vehicle analysis constitute the most important foundation for intelligent urban computing. There applications are becoming pervasive in the field of urban planning, transportation systems, environmental conservation, energy consumption, economy, and public security.
    </p>
    <p>
        The goal of this workshop is to: 1) bring together the state of the art research on human and vehicle analysis for intelligent urban computing; 2) call for a coordinated effort to understand the opportunities and challenges emerging in human and vehicle analysis; 3) identify key tasks and evaluate the state-of-the-art methods; 4) showcase innovative methodologies and ideas; 5) introduce interesting real-world intelligent urban computing systems or applications; and 6) propose new real-world datasets and discuss future directions. We solicit original contributions in all fields of human and vehicle analysis that explore the big data in big cities to help us understand the nature of urban phenomena and even predict the future of cities. We believe the workshop will offer a timely collection of research updates to benefit the researchers and practitioners working in the broad computer vision, multimedia, and pattern recognition communities. To this end, we solicit original research and survey papers in (but not limited to) the following topics:
        <div>
            <ul>
                <li>Face detection, face recognition, and face anti-spoofing</li>
                <li>Face landmark detection and face parsing</li>
                <li>Human detection, pose estimation, human parsing, and pose tracking</li>
                <li>Human 3D shape estimation and reconstruction</li>
                <li>Human gait recognition, person re-identification and person tracking</li>
                <li>Human action recognition and trajectory recognition/prediction</li>
                <li>City-scale vehicle detection, recognition and parsing</li>
                <li>City-scale vehicle tracking and re-identification</li>
                <li>Vehicle license plate recognition and super-resolution</li>
            </ul>
        </div>
    </p>    
</div>

<div name='programs'>
    <h1>

        <a id="header-2" class="anchor" href="#header-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>
        Tentative Programs
    </h1>
    <div>
        <h2>Time</h2>
        half-day, about 4 hours
    </div>
    <div>
        <h2>Schedule</h2>
    <ul>
    <li>Welcome and opening (10 min)</li>    
    <li>Invited Talk 1: <strong>"Challenges in Face Recognition and Solutions", Prof. Stan Z. Li, Chinese Academy of Sciences, China</strong>(40 min)</li>    
    <li>Invited Talk 2: <strong>"Autonomous Driving Technologies", Dr. Xu Han, CEO, WeRide Company</strong> (40 min)</li>    
    <li>Invited Talk 3: <strong>Prof. Yi Yang, University of Technology Sydney, Australia</strong>> (40 min)</li>    
    <li>Coffee Break (25 min.)</li>    
    <li>5 oral presentations (15 min. each)</li>    
    <li>Discussion and closing (10 min.)</li>    
    </ul>
    </div>
</div>
<div>
    <h1>
        <a id="header-3" class="anchor" href="#header-3" aria-hidden="true"><span class="octicon octicon-link"></span></a>
        Reviewing process
    </h1>
    <p>The full paper submission deadline will be around July 1 and the decisions will be out on July 15. Each paper will be reviewed by at least two reviewers using a double-blind review process.</p>
</div>
<div name='Organizers'>
    <h1>
        <a id="header-4" class="anchor" href="#header-4" aria-hidden="true"><span class="octicon octicon-link"></span></a>
        Organizers
    </h1>
    <div>
        <h2>Wu Liu, JD AI Research, Beijing, China</h2>
        <!-- <img src='./img/liu.jpg' height="200" width="200"/> -->
        <img src="./img/liu.jpg" width="200" height="200" style="float:left; margin: 5px;" />
        <div name='bio'>
            <p style="text-indent:2em;">
                Dr. Wu Liu is a Senior Researcher in JD AI Research, China. His current research interests include human behavior analysis and 
                intelligent video surveillance. He received his Ph.D. degree from the Institute of Computing Technology, 
                Chinese Academy of Science in 2015. 
                He has published more than 60 papers in prestigious conferences and journals in computer vision and multimedia. 
                He received IEEE Trans. On Multimedia 2019 Prize Paper Award, IEEE Multimedia 2018 Best Paper Award, 
                IEEE ICME 2016 Best Student Paper Award, and Chinese Academy of Sciences Outstanding Ph.D. Thesis Award in 2016, etc. 
                He also won the 1st Place in the single and multi-person pose estimation tasks in CVPR 2018 Look into Person Challenge. 
                Dr. Liu is the founding committee member of ACM FCA, and the committee member of IEEE CASS-MSA. 
                He has also served as the Web Chair of IEEE ICME 2019, Publicity Chair of IEEE BIGMM 2018, and the Area Chairs of ACM MM 2019, ICME 2019, ICIP 2017, etc.
            </p>
            <p style="text-indent:2em;">
                Dr. Wu Liu also organized the tutorials “Human Behavior Understanding: From Human-Oriented Analysis 
                to Action Recognition” in ICME 2019, the tutorials “Human-centric Visual Understanding” in ACM Multimedia Asia 2019, 
                the special issue on “Intelligent Urban Computing with Big Data” in MVA 2018, 
                and the special issue on “Intelligent Analytics for Big Video Data” in MTAP 2019.
            </p>
        </div>
        <div name='papers'>
            <h2>Selected Papers</h2>
            <ol>
                <li>Xinchen Liu, Wu Liu, Tao Mei, Huadong Ma: PROVID: Progressive and Multimodal Vehicle Reidentification for Large-Scale Urban Surveillance. IEEE Trans. Multimedia 20(3): 645-658 (2018) <b>(2019 Prize Paper Award)</b></li>
                <li>Huadong Ma, Wu Liu: A Progressive Search Paradigm for the Internet of Things. IEEE Multimedia 25(1): 76-86 (2018) <b>(2018 Best Paper Award)</b></li>
                <li>Xinchen Liu, Wu Liu, Huadong Ma, Huiyuan Fu: Large-scale vehicle re-identification in urban surveillance videos. ICME 2016: 1-6 <b>(2016 Best Student Paper)</b></li>
                <li>Weijian Ruan, Wu Liu, Qian Bao, Jun Chen, Yuhao Cheng, Tao Mei: POINet: Pose-Guided Ovonic Insight Network for Multi-Person Pose Tracking. ACM Multimedia 2019: 284-292</li>
                <li>Xinchen Liu, Wu Liu, Meng Zhang, Jingwen Chen, Lianli Gao, Chenggang Yan, Tao Mei: Social Relation Recognition From Videos via Multi-Scale Spatial-Temporal Reasoning. CVPR 2019: 3566-3574</li>
            </ol>
        </div>
    </div>
    <div>
        <h2>Hailin Shi, JD AI Research, Beijing, China</h2>
        <img src='./img/hailing.jpg' width="200" style="float:left; margin: 5px;"/>
        <div name='bio'>
            <p style="text-indent:2em;">
                Dr. Hailin Shi receives his Ph.D. from the Institute of Automation, Chinese Academy of Sciences, 
                under the supervision of Prof. Stan Z. Li. He is currently a Senior Researcher at JD AI, 
                with research interests in the area of face recognition, object detection, semi-supervised learning, etc. 
                He makes several works published and provides review services in conferences and journals (CVPR, ICCV, ECCV, AAAI, IJCV) of 
                computer vision and pattern recognition. His team has gained the first place in WIDER FACE leaderboard 2019, the first place in the Real-World Low-Quality Face Recognition challenge (ICCV2019) and the second place in Lightweight Face Recognition challenge (ICCV2019), 
                and has applied 20 face-recognition-related patents which are used in JD on-&off-line retailing and campus products
            </p>
        </div>
        <div name='papers'>
            <h2>Selected Papers</h2>
            <ol>
                <li>Hailin Shi, Yang Yang, Xiangyu Zhu, Shengcai Liao, Zhen Lei, Wei-Shi Zheng, Stan Z. Li: Embedding Deep Metric for Person Re-identification: A Study Against Large Variations. ECCV (1) 2016: 732-748</li>
                <li>Xiaobo Wang, Shuo Wang, Hailin Shi, Jun Wang, Tao Mei: Co-Mining: Deep Face Recognition with Noisy Labels. ICCV 2019 <b>(Oral)</b></li>
                <li>Rui Zhu, Shifeng Zhang, Xiaobo Wang, Longyin Wen, Hailin Shi, Liefeng Bo, Tao Mei: ScratchDet: Training Single-Shot Object Detectors From Scratch. CVPR 2019: 2268-2277 <b>(Oral)</b></li>
                <li>Shifeng Zhang, Longyin Wen, Hailin Shi, Zhen Lei, Siwei Lyu, Stan Z. Li: Single-Shot Scale-Aware Network for Real-Time Face Detection. International Journal of Computer Vision 127(6-7): 537-559 (2019)</li>
                <li>Yinglu Liu, Hailin Shi, Hao Shen, Yue Si, Xiaobo Wang, Tao Mei: A New Dataset and Boundary-Attention Semantic Segmentation for Face Parsing. AAAI 2020</li>
            </ol>
        </div>
    </div>
    <div>
        <h2>Yunchao Wei, University of Technology Sydney, Australia</h2>
        <img src='./img/yuchao.jpg' width="200" style="float:left; margin: 5px;"/>
        <div name='bio'>
            <p style="text-indent:2em;">
                Yunchao Wei is an Assistant Professor with the Faculty of Engineering and IT at the University of Technology Sydney. 
                He received his Ph.D. degree from Beijing Jiaotong University in 2016. He authored/co-authored more than 50 high-quality technical papers, Google Citation 2500+. 
                He received the 1st prize in science and technology award from China Society of Image and Graphics in 2019, Discovery Early Career Researcher Award of Australian Research Council in 2018, 
                1st place of all human parsing tracks in the 2nd LIP Challenge, Excellent Doctoral Dissertation Awards of Chinese Institute of Electronics (CIE) in 2016, and 1st place of object detection task in ILSVRC 2014. 
                He organizes the workshop on Learning from Imperfect Data (LID) in CVPR 2019, 2020, Real-World Recognition from Low-Quality Images and Videos (RLQ) in ICCV 2019, Look Into Person (LIP) in CVPR 2019. 
                His research interests mainly lie in machine learning in general, including deep learning, large-scale machine learning and their applications in computer vision such as object detection and semantic segmentation.
            </p>
        </div>
        <div name='papers'>
            <h2>Selected Papers</h2>
            <ol>
                <li>Bowen Cheng, Liang-Chieh Chen, Yunchao Wei, Yukun Zhu, Zilong Huang, Jinjun Xiong, Thomas Huang, Wen-Mei Hwu, Honghui Shi: SPGNet: Semantic Prediction Guidance for Scene Parsing. ICCV 2019</li>
                <li>Zilong Huang, Xinggang Wang, Lichao Huang, Chang Huang, Yunchao Wei, Wenyu Liu: CCNet: Criss-Cross Attention for Semantic Segmentation. ICCV 2019</li>
                <li>Yang Fu, Yunchao Wei, Guanshuo Wang, Xi Zhou, Honghui Shi, Thomas S. Huang: Self-similarity Grouping: A Simple Unsupervised Cross Domain Adaptation Approach for Person Re-identification. ICCV 2019 <b>(Oral)</b></li>
                <li>Yang Fu, Xiaoyang Wang, Yunchao Wei, Thomas Huang: STA: Spatial-Temporal Attention for Large-Scale Video-Based Person Re-Identification. AAAI 2019: 8287-8294</li>
                <li>Yang Fu, Yunchao Wei, Yuqian Zhou, Honghui Shi, Gao Huang, Xinchao Wang, Zhiqiang Yao, Thomas Huang: Horizontal Pyramid Matching for Person Re-Identification. AAAI 2019: 8295-8302</li>
            </ol>
        </div>
    </div>
    <div>
        <h2>Dan Zeng, Shanghai University, China</h2>
        <img src='./img/dan.jpg' width="200" style="float:left; margin: 5px;"/>
        <div name='bio'>
            <p style="text-indent:2em;">
                Dr. Zeng is a full professor at the Institute of Advanced Communication and Data Science, Shanghai University (SHU), China. She is currently the Dean of the Department of 
                Communication Engineering. Dr. Zeng received her Ph.D. degree in 2008, and her B.S. degree in 2003, both from the University of Science and Technology of China (USTC). 
                Dr. Zeng is the recipient of the 2008 Outstanding PhD Graduate of Anhui Province. She has 10+ years’ post-Ph.D. research experience, 2 years’ on-leave position at industry, 
                and 30+ publications in computer vision and multimedia analysis. Her main research interests include computer vision, multimedia analysis, and machine learning. 
                Dr. Zeng was the Local Event Chair of IEEE International Conference on Multimedia & Expo (ICME) 2019 and the Area Chair of 
                IEEE Visual Communications and Image Processing (VCIP) 2018. She serves in the editorial boards of the journal of Shanghai University.
            </p>
        </div>
        <div name='papers'>
            <h2>Selected Papers</h2>
            <ol>
                <li>Dan Zeng, Han Liu, Fan Zhao, Shiming Ge, Wei Shen, Zhijiang Zhang: Proposal pyramid networks for fast face detection. Inf. Sci. 495: 136-149 (2019) [2] Dan Zeng, Shun Zhang, Fansheng Chen, Yueming Wang: Multi-Scale CNN Based Garbage Detection of Airborne Hyperspectral Data. IEEE Access 7: 104514-104527 (2019)</li>
                <li>Dan Zeng, Fan Zhao, Shiming Ge, Wei Shen: Fast cascade face detection with pyramid network. Pattern Recognition Letters 119: 180-186 (2019) </li>  
                <li>Dan Zeng, Fan Zhao, Wei Shen, Shiming Ge: Compressing and Accelerating Neural Network for Facial Point Localization. Cognitive Computation 10(2): 359-367 (2018)</li>  
                <li>Qinzhu He, Yijun Ji, Dan Zeng, Zhijiang Zhang: Volumeter: 3D human body parameters measurement with a single Kinect. IET Computer Vision 12(4): 553-561 (2018)</li>  
            </ol>
        </div>
    </div>
    <div>
        <h2>Jiebo Luo, University of Rochester, USA</h2>
        <img src='./img/jiebo.jpg' width="200" style="float:left; margin: 5px;"/>
        <div name='bio'>
            <p style="text-indent:2em;">
                Jiebo Luo is a Professor of Computer Science at the University of Rochester. He has authored more than 400 technical papers and holds more than 90 U.S. patents. 
                His research interests include computer vision, machine learning, data mining, social media, and biomedical informatics. He has served as the Program Chair for ACM Multimedia 2010, 
                IEEE CVPR 2012, ACM ICMR 2016, and IEEE ICIP 2017, and on the editorial boards of the IEEE Transactions on Pattern Analysis and Machine Intelligence, IEEE Transactions on 
                Multimedia, IEEE Transactions on Circuits and Systems for Video Technology, IEEE Transactions on Big Data, Pattern Recognition, Machine Vision and Applications, and the 
                ACM Transactions on Intelligent Systems and Technology. He is serving as the Editor-in-Chief of the IEEE Transactions on Multimedia from 2020 to 2022. He is also a fellow of 
                ACM, AAAI, SPIE, and IAPR.
            </p>
        </div>
        <div name='papers'>
            <h2>Selected Papers</h2>
            <ol>
                <li>Zhengyuan Yang, Yuncheng Li, Jianchao Yang, Jiebo Luo: Action Recognition With Spatio-Temporal Visual Attention on Skeleton Image Sequences. IEEE Trans. Circuits Syst. Video Techn. 29(8): 2405-2415 (2019)</li>
                <li>Fuchen Long, Ting Yao, Zhaofan Qiu, Xinmei Tian, Jiebo Luo, Tao Mei: Gaussian Temporal Awareness Networks for Action Localization. CVPR 2019: 344-353</li>
                <li>Jingyi Hou, Xinxiao Wu, Jin Chen, Jiebo Luo, Yunde Jia: Unsupervised Deep Learning of Mid-Level Video Representation for Action Recognition. AAAI 2018: 6910-6917</li>
                <li>Yang Feng, Jiebo Luo: When do luxury cars hit the road? Findings by a big data approach. BigData 2016: 2470-2474</li>
                <li>Jingen Liu, Jiebo Luo, Mubarak Shah: Recognizing realistic actions from videos. CVPR 2009: 1996-2003</li>
            </ol>
        </div>
    </div>
</div>
<footer class="site-footer">
    <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
</footer>
</section>
</body>
</html>